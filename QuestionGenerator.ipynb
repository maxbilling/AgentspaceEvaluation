{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsjqa60k0cF1+6juP1ly2c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxbilling/AgentspaceEvaluation/blob/main/QuestionGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automatic Question Answer Pair Generation from GCS source files"
      ],
      "metadata": {
        "id": "xQAj1DrKNul7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Python script automates the creation of a question-and-answer dataset from PDF files stored in Google Cloud Storage (GCS). It iterates through each PDF in a specified GCS bucket, using the Vertex AI Gemini Pro model to read the document's content and generate two context-specific questions and their corresponding answers. The script then compiles these generated pairs, along with a direct URI link to the source PDF, into a single CSV file. Finally, it uploads this CSV back to the GCS bucket, providing a ready-to-use dataset for evaluating search or question-answering systems."
      ],
      "metadata": {
        "id": "1CD_FPSiO89E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-storage google-generativeai"
      ],
      "metadata": {
        "id": "MZa9spxnNsnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user(project_id=project)"
      ],
      "metadata": {
        "id": "dov5t0VEOUOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IlEx0YNNrsT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import io\n",
        "import csv\n",
        "import datetime\n",
        "import google.auth\n",
        "\n",
        "# Import the necessary Google Cloud libraries\n",
        "from google.cloud import storage\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part\n",
        "\n",
        "\n",
        "# --- Configuration ---\n",
        "# âš ï¸ CHANGE these to match your GCP environment and bucket\n",
        "GCP_PROJECT_ID = \"\" # @param\n",
        "GCP_REGION = \"europe-west1\" # Or your specific region\n",
        "BUCKET_NAME = \"\"# @param\n",
        "\n",
        "# The folder where the PDFs are stored\n",
        "PDF_FOLDER = \"wikipedia-articles/\"\n",
        "\n",
        "# The name for the output CSV file\n",
        "CSV_OUTPUT_FILENAME = \"input_queries.csv\"\n",
        "\n",
        "\n",
        "GEMINI_PROMPT = \"\"\"\n",
        "Based on the Wikipedia article attached, generate two questions that can be answered with the information in the PDF.\n",
        "The questions should not be generic but detailed enough that they can be answered only with the information in the PDF.\n",
        "Respond ONLY in the following format, with each Q&A pair on a new line:\n",
        "search_query;expected_answer\n",
        "Ensure that question and answer are always filled. If you cannot generate a question and answer pair reponde with \"could not genreate question\"; \"could not generate answer\".\n",
        "\"\"\"\n",
        "# --- End of Configuration ---\n",
        "\n",
        "def list_pdf_blobs(storage_client, bucket_name, folder_name):\n",
        "    print(f\"ðŸ” Searching for PDF files in gs://{bucket_name}/{folder_name}...\")\n",
        "    blobs = storage_client.list_blobs(bucket_name, prefix=folder_name)\n",
        "    pdf_blobs = [blob for blob in blobs if blob.name.lower().endswith(\".pdf\")]\n",
        "    print(f\"âœ… Found {len(pdf_blobs)} PDF files.\")\n",
        "    return pdf_blobs\n",
        "\n",
        "def generate_qna_from_pdf(model, pdf_blob):\n",
        "    print(f\"ðŸ§  Processing '{pdf_blob.name}' with Vertex AI Gemini...\")\n",
        "    try:\n",
        "        pdf_content = pdf_blob.download_as_bytes()\n",
        "        pdf_file_for_api = Part.from_data(data=pdf_content, mime_type=\"application/pdf\")\n",
        "        request_payload = [GEMINI_PROMPT, pdf_file_for_api]\n",
        "        response = model.generate_content(request_payload)\n",
        "        qna_pairs = []\n",
        "        for line in response.text.strip().split('\\n'):\n",
        "            if ';' in line:\n",
        "                parts = line.split(';', 1)\n",
        "                if len(parts) == 2:\n",
        "                    qna_pairs.append({\"search_query\": parts[0].strip(), \"expected_answer\": parts[1].strip()})\n",
        "        if not qna_pairs:\n",
        "            print(f\"âš ï¸ Warning: Could not parse Q&A from response for {pdf_blob.name}.\")\n",
        "        else:\n",
        "            print(f\"ðŸ‘ Successfully generated {len(qna_pairs)} Q&A pairs.\")\n",
        "        return qna_pairs\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ An error occurred while processing {pdf_blob.name}: {e}\")\n",
        "        return []\n",
        "\n",
        "# MODIFIED FUNCTION\n",
        "import urllib.parse\n",
        "\n",
        "def generate_mtls_url(blob):\n",
        "    \"\"\"\n",
        "    Generates a permanent, authenticated mTLS URL for a GCS blob.\n",
        "\n",
        "    This URL requires the user to authenticate via IAM and mTLS. Spaces in the\n",
        "    object name are correctly URL-encoded.\n",
        "    \"\"\"\n",
        "    # Get the bucket and object names from the blob object.\n",
        "    bucket_name = blob.bucket.name\n",
        "    object_name = blob.name\n",
        "\n",
        "    # URL-encode the object name to handle spaces (e.g., ' ' -> '%20')\n",
        "    # and other special characters, while keeping '/' for folder paths.\n",
        "    encoded_object_name = urllib.parse.quote(object_name, safe='/')\n",
        "\n",
        "    # Construct the URL using the specified format.\n",
        "    mtls_url = f\"gs://{bucket_name}/{object_name}\"\n",
        "\n",
        "    return mtls_url\n",
        "\n",
        "def upload_csv_to_gcs(storage_client, bucket_name, destination_path, data):\n",
        "    if not data:\n",
        "        print(\"No data to upload. Skipping CSV creation.\")\n",
        "        return\n",
        "    string_io = io.StringIO()\n",
        "    fieldnames = ['search_query', 'expected_answer', 'golden_url']\n",
        "    writer = csv.DictWriter(string_io, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(data)\n",
        "    csv_data = string_io.getvalue()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(destination_path)\n",
        "    blob.upload_from_string(csv_data, content_type='text/csv')\n",
        "    print(f\"\\nâœ… Successfully uploaded results to gs://{bucket_name}/{destination_path}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    credentials, project = google.auth.default()\n",
        "\n",
        "    try:\n",
        "        vertexai.init(project=GCP_PROJECT_ID, location=GCP_REGION)\n",
        "        model = GenerativeModel(\"gemini-2.5-flash\")\n",
        "        storage_client = storage.Client()\n",
        "\n",
        "        pdf_blobs = list_pdf_blobs(storage_client, BUCKET_NAME, PDF_FOLDER)\n",
        "        if not pdf_blobs:\n",
        "            return\n",
        "\n",
        "        all_results = []\n",
        "        for i, blob in enumerate(pdf_blobs):\n",
        "            print(\"-\" * 50)\n",
        "            print(f\"Processing file {i+1} of {len(pdf_blobs)}\")\n",
        "            qna_list = generate_qna_from_pdf(model, blob)\n",
        "            if qna_list:\n",
        "                # MODIFIED FUNCTION CALL\n",
        "                golden_url = generate_mtls_url(blob)\n",
        "                for item in qna_list:\n",
        "                    all_results.append({**item, \"golden_url\": golden_url})\n",
        "\n",
        "        csv_destination_path = f\"{PDF_FOLDER.strip('/')}/{CSV_OUTPUT_FILENAME}\"\n",
        "        upload_csv_to_gcs(storage_client, BUCKET_NAME, csv_destination_path, all_results)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn unexpected error occurred during initialization or execution: {e}\")\n",
        "\n",
        "# --- Run the main function ---\n",
        "main()\n",
        "\n"
      ]
    }
  ]
}